{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "QmhbuFBP2snd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words=set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbE_e_MM25Gn",
        "outputId": "9994e4d6-2261-425d-df2d-24100943298c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text=input(\"enter a text\")\n",
        "words=re.sub(r'[^\\w\\s]',\"\",text).split() #remove punctuation\n",
        "filtered_words=[word for word in words if word not in stop_words]\n",
        "print(stop_words)\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09J0U7HG4AX_",
        "outputId": "95052235-2218-4c55-fb7a-65331cef31a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter a textHi, I am Santhiya!\n",
            "{\"mightn't\", \"you'll\", 'yours', \"she'd\", \"you'd\", 'won', 'aren', 'against', 'a', 'yourself', \"they'd\", \"shouldn't\", 'it', 'just', \"it's\", 'whom', 's', 'an', 'mightn', 'for', \"they'll\", 'wouldn', 'from', 'how', 'theirs', 'can', 'all', 'had', 'him', 'herself', \"we've\", 'above', 'or', 'their', 'then', 'should', \"wouldn't\", 'hasn', 'at', 'ourselves', 'what', 'while', \"weren't\", 'each', \"hasn't\", 'ours', 'after', 'didn', 'ain', 'but', 'having', 'here', 'doing', 'them', 'we', 'isn', 'before', 'be', 'again', 'are', \"mustn't\", 'do', 'and', 'where', 'your', 'more', 'between', 'in', \"you've\", \"she's\", 'too', 'is', 'd', 'my', \"hadn't\", 'nor', 'couldn', 're', 'once', 'during', 'me', 'shan', 'of', 'most', \"it'll\", 'have', 'the', 'few', 'about', 'on', 'as', 'he', 'there', 'very', 'why', \"aren't\", \"isn't\", 'was', 'other', 'haven', \"i'll\", \"couldn't\", 'y', 'being', 'such', 'has', 'down', 'because', \"needn't\", 'that', \"shan't\", 'until', 'shouldn', \"i've\", 'itself', 'both', 'her', 'weren', \"won't\", 'some', 'through', 'any', 'only', 'so', 'now', 'which', 'same', 'll', 'will', 'yourselves', 'its', 'further', 't', 'doesn', 'this', \"we'd\", 'if', 'mustn', 'over', \"we'll\", 'into', 'myself', 'not', \"they're\", 'does', 'am', 'themselves', \"haven't\", \"you're\", \"he's\", \"i'm\", 'our', 'no', 'by', 'off', 'needn', \"that'll\", 'with', 'don', 'were', \"didn't\", \"should've\", 'own', 'did', 'hadn', 'm', 'under', \"doesn't\", 'who', 'himself', 'to', \"don't\", 'hers', 'i', \"he'd\", \"she'll\", \"we're\", 've', 'she', 'o', \"wasn't\", 'these', 'up', 'they', 'wasn', 'been', \"it'd\", 'ma', \"they've\", \"i'd\", 'his', \"he'll\", 'than', 'out', 'those', 'when', 'below', 'you'}\n",
            "['Hi', 'I', 'Santhiya']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "next file loading method"
      ],
      "metadata": {
        "id": "VFfuQ92xB8jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "with open(\"/content/story.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text = file.read()\n",
        "words=re.sub(r'[^\\w\\s]',\"\",text).split() #remove punctuation\n",
        "filtered_words=[word for word in words if word not in stop_words]\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYp9Jk5IBDi-",
        "outputId": "c66a0444-56de-482a-c267-88d3b5457dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['There', 'isnt', 'one', 'single', 'best', 'story', 'English', 'subjective', 'depends', 'individual', 'preferences', 'However', 'widely', 'acclaimed', 'popular', 'stories', 'include', 'The', 'Lottery', 'Shirley', 'Jackson', 'The', 'Old', 'Man', 'Sea', 'Ernest', 'Hemingway', 'The', 'Happy', 'Prince', 'Oscar', 'Wilde', 'Classic', 'childrens', 'stories', 'like', 'The', 'Tortoise', 'Hare', 'The', 'Three', 'Little', 'Pigs', 'also', 'beloved', 'widely', 'read', 'A', 'chilling', 'unsettling', 'story', 'exploring', 'themes', 'conformity', 'tradition', 'Its', 'classic', 'example', 'story', 'leaves', 'lasting', 'impact', 'reader']\n"
          ]
        }
      ]
    }
  ]
}